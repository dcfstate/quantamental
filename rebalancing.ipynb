{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rebalancing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABvyoTLS8x_J"
      },
      "source": [
        "**Disclosure:** I am not responsible for any losses that may occur if you choose to employ this rebalancing strategy in a live trading environment. The code and accompanying commentary are strictly for informational purposes. Nothing in this document should be construed as a recommendation for or against a financial services product, trading strategy, portfolio strategy, or any specific asset.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "My bases for the LSTM module:\r\n",
        "- Github: [Google Stock Price Prediction Using RNN-LSTM](https://github.com/ms723528/Google-Stock-Price-Prediction-Using-RNN---LSTM)\r\n",
        "- Github: CFA Institute Webinar: Neural Networks in Action (Apr 2020) [link text](https://github.com/kritim13/cfa_neural_networks_in_action_2020)\r\n",
        "\r\n",
        "My basis for the portfolio rebalancing module:\r\n",
        "- [Portfolio Selection with Graph Algorithms and Deep Learning](https://www.linkedin.com/pulse/portfolio-selection-graph-algorithms-deep-learning-maya-benowitz/)\r\n",
        "- Github: [Hedgecraft](https://github.com/mayabenowitz/Hedgecraft)\r\n",
        "\r\n",
        "Generally helpful in constructing the Alpaca API modules:\r\n",
        "- Youtube: [Part Time Larry](https://www.youtube.com/c/parttimelarry/videos)\r\n",
        "- [Alpaca API Documentation](https://alpaca.markets/docs/api-documentation/api-v2/)\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "**How it Works: Modules and Dataflow**\r\n",
        "\r\n",
        "Put simply, the entire Colab notebook is composed of four modules, each performing one primary function:\r\n",
        "1. Requesting end-of-day price data for your stocks via Alpaca's API.\r\n",
        "2. Running the price data through a LSTM algorithm to predict the EOD price for the next trading day.\r\n",
        "3. Running the historical + predicted price data for all your stocks through a portfolio optimization algorithm (Hedgecraft) to obtain optimal portfolio allocation.\r\n",
        "4. Buying/selling discrete stock units through Alpaca's API to realize this optimal portfolio allocation.\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "How to run the algorithm in 8 steps\r\n",
        "1. Apply for an Alpaca account (may take 1-2 days for approval)\r\n",
        "2. After you're approved, set up Paper Trading in your Alpaca account\r\n",
        "3. Copy the code from the Google Colab notebook provided\r\n",
        "4. In cell 2, assign your Alpaca ID and Secret Key to \"APCA_API_KEY_ID\" and \"APCA_API_SECRET_KEY\", respectively.\r\n",
        "5. In cell 2, input the tickers you want in your portfolio into \"target_list\"\r\n",
        "6. Make sure it's between 930-1600 EST on a trading day\r\n",
        "7. Press Ctrl+F9 or click \"Runtime\" -> \"Run All\" to run the notebook\r\n",
        "8. Check your Alpaca Paper Trading account online\r\n",
        "Done. \r\n",
        "(Note: You can set LSTM \"epochs\" to \"1\" if you want to just run the notebook to see that it works. If you're running the Colab notebook with the default # of epochs, I recommend that you enable the GPU hardware accelerator in \"Runtime\" -> \"Change runtime type\" to save time.)\r\n",
        "\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "\r\n",
        "[Link](https://drive.google.com/file/d/1l5tMJBX5ZEGcc6chH0cvjzITcmdZU9jp/view?usp=sharing) to Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keNu79-6zFl6"
      },
      "source": [
        "!pip3 install dcor\r\n",
        "!pip3 install networkx\r\n",
        "!pip3 install PyPortfolioOpt\r\n",
        "!pip3 install alpaca-trade-api\r\n",
        "!pip3 install trading-calendars\r\n",
        "\r\n",
        "\r\n",
        "import alpaca_trade_api as tradeapi\r\n",
        "import requests, json\r\n",
        "\r\n",
        "import dcor\r\n",
        "import networkx as nx\r\n",
        "from pypfopt import discrete_allocation\r\n",
        "from pypfopt.expected_returns import mean_historical_return\r\n",
        "from pypfopt.efficient_frontier import EfficientFrontier\r\n",
        "\r\n",
        "import sklearn\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from datetime import datetime\r\n",
        "from datetime import date\r\n",
        "import pytz\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4Xe4JZl6vsy"
      },
      "source": [
        "#Put your target companies in \"target_list\"\r\n",
        "#There may be a upper bound to the number of tickers as bounded by Alpaca's API when requesting datasets of daily prices\r\n",
        "target_list = ['AMZN', 'MA', 'GOOG', 'ADBE', 'MSFT', 'AAPL', 'V', 'DIS', 'DPZ', 'PYPL', 'FB', 'COST']\r\n",
        "\r\n",
        "#Lower bound to daily price data you will be requesting from Alpaca\r\n",
        "start_date = '2018-01-01'\r\n",
        "\r\n",
        "#Input your Alpaca ID & Secret Key so that you can access Alpaca's API endpoint from this notebook \r\n",
        "APCA_API_KEY_ID = \r\n",
        "APCA_API_SECRET_KEY = \r\n",
        "\r\n",
        "#This URL is used as a base url for accessing different endpoints\r\n",
        "#DO NOT change BASE_URL to the live Alpaca URL unless you know what you are doing\r\n",
        "#I am not responsible for any trading losses that may occur if you switch from Paper Trading to Live Trading\r\n",
        "BASE_URL = 'https://paper-api.alpaca.markets'\r\n",
        "\r\n",
        "#Change 'US/Eastern' to your own timezone\r\n",
        "now = datetime.now(pytz.timezone('US/Eastern'))\r\n",
        "\r\n",
        "#The number of days you want the LSTM model to use as the lookback period\r\n",
        "lookback = 60\r\n",
        "\r\n",
        "#Keep training_pct as 1.0 to use 100% of daily prices as training data\r\n",
        "#This is a naive form of an online LSTM\r\n",
        "training_pct = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7sLbrRjVouR"
      },
      "source": [
        "#############################################################################\r\n",
        "def df_distance_correlation(df_train):\r\n",
        "    df_train_dcor = pd.DataFrame(index=stocks, columns=stocks)\r\n",
        "    k=0\r\n",
        "\r\n",
        "    for i in stocks:\r\n",
        "        v_i = df_train.loc[:, i].values\r\n",
        "        for j in stocks[k:]:\r\n",
        "            v_j = df_train.loc[:, j].values\r\n",
        "            dcor_val = dcor.distance_correlation(v_i, v_j)\r\n",
        "            df_train_dcor.at[i,j] = dcor_val\r\n",
        "            df_train_dcor.at[j,i] = dcor_val\r\n",
        "        k+=1\r\n",
        "\r\n",
        "    return df_train_dcor\r\n",
        "#############################################################################\r\n",
        "def build_corr_nx(df_train):\r\n",
        "    cor_matrix = df_train.values.astype('float')\r\n",
        "    sim_matrix = 1 - cor_matrix\r\n",
        "    \r\n",
        "    G = nx.from_numpy_matrix(sim_matrix)\r\n",
        "    stock_names = df_train.index.values\r\n",
        "    G = nx.relabel_nodes(G, lambda x: stock_names[x])\r\n",
        "\r\n",
        "    G.edges(data=True)\r\n",
        "    H = G.copy()\r\n",
        "    \r\n",
        "    for (u, v, wt) in G.edges.data('weight'):\r\n",
        "        if wt >= 1 - 0.325:\r\n",
        "            H.remove_edge(u, v)\r\n",
        "        if u == v:\r\n",
        "            H.remove_edge(u, v)\r\n",
        "     \r\n",
        "    return H\r\n",
        "#############################################################################\r\n",
        "def centrality_to_portfolio_weights(weights):\r\n",
        "    for key, value in weights.items():\r\n",
        "        weights[key] = 1/value\r\n",
        "    norm = 1.0 / sum(weights.values())\r\n",
        "\r\n",
        "    for key in weights:\r\n",
        "        weights[key] = round(weights[key] * norm, 3)\r\n",
        "    return weights\r\n",
        "#############################################################################\r\n",
        "def get_account():\r\n",
        "    r = requests.get(ACCOUNT_URL, headers=HEADERS)\r\n",
        "\r\n",
        "    return json.loads(r.content)\r\n",
        "#############################################################################\r\n",
        "def create_order(symbol, qty, side, type, time_in_force):\r\n",
        "    data = {\r\n",
        "        \"symbol\": symbol,\r\n",
        "        \"qty\": qty,\r\n",
        "        \"side\": side,\r\n",
        "        \"type\": type,\r\n",
        "        \"time_in_force\": time_in_force\r\n",
        "    }\r\n",
        "\r\n",
        "    r = requests.post(ORDERS_URL, json=data, headers=HEADERS)\r\n",
        "\r\n",
        "    return json.loads(r.content)\r\n",
        "#############################################################################\r\n",
        "def get_orders():\r\n",
        "    r = requests.get(ORDERS_URL, headers=HEADERS)\r\n",
        "\r\n",
        "    return json.loads(r.content)\r\n",
        "#############################################################################\r\n",
        "ACCOUNT_URL = \"{}/v2/account\".format(BASE_URL)\r\n",
        "ORDERS_URL = \"{}/v2/orders\".format(BASE_URL)\r\n",
        "HEADERS = {'APCA-API-KEY-ID': APCA_API_KEY_ID, 'APCA-API-SECRET-KEY': APCA_API_SECRET_KEY}\r\n",
        "api = tradeapi.REST(APCA_API_KEY_ID, APCA_API_SECRET_KEY, base_url=BASE_URL)\r\n",
        "account = api.get_account()\r\n",
        "today = date.today()\r\n",
        "clock = api.get_clock()\r\n",
        "#############################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orlvj37xnXe3"
      },
      "source": [
        "stuff = []\r\n",
        "for i in target_list:\r\n",
        "  globals()[i] =  api.polygon.historic_agg_v2(i , 1, 'day', _from=start_date, to=today).df\r\n",
        "  globals()[i]['Ticker'] = i\r\n",
        "  stuff.append(globals()[i])\r\n",
        "\r\n",
        "empty = stuff[0].iloc[:0,:]\r\n",
        "for i in range(0, len(stuff)):\r\n",
        "  empty = empty.append(stuff[i])\r\n",
        "\r\n",
        "\r\n",
        "empty_close = empty.pivot(columns='Ticker', values='close')\r\n",
        "empty_close_copy = empty_close.copy()\r\n",
        "\r\n",
        "data_training_raw, data_test_raw = np.split(empty_close, [int(training_pct*len(empty_close))])\r\n",
        "array_data_training = empty_close.values\r\n",
        "\r\n",
        "date_index = pd.DataFrame(data_training_raw.index)\r\n",
        "for i in range(0, len(date_index)):\r\n",
        "  date_index.iloc[i,0] = date_index.iloc[i,0].date()\r\n",
        "\r\n",
        "date_index = date_index[lookback:]\r\n",
        "date_index = date_index.reset_index().iloc[:,1:]\r\n",
        "date_index.loc[len(date_index)] = clock.next_open.date()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEQ3UY8vyag8"
      },
      "source": [
        "historical_prices_plus_one = date_index\r\n",
        "\r\n",
        "for c in range(0, len(target_list)):\r\n",
        "      X_train = []\r\n",
        "      y_train = []\r\n",
        "\r\n",
        "      print(target_list[c])\r\n",
        "\r\n",
        "      for i in range(lookback, array_data_training.shape[0]):\r\n",
        "          X_train.append(array_data_training[i-lookback:i])\r\n",
        "          y_train.append(array_data_training[i, c])\r\n",
        "\r\n",
        "      X_train, y_train = np.asarray(X_train).astype('float32'), np.asarray(y_train).astype('float32')\r\n",
        "      X_train, y_train = np.array(X_train), np.array(y_train)\r\n",
        " \r\n",
        "\r\n",
        "      model = Sequential()\r\n",
        "      model.add(LSTM(units = 60, activation = 'tanh', return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\r\n",
        "      model.add(Dropout(0.5))\r\n",
        "      model.add(LSTM(units = 60, activation = 'tanh', return_sequences = True))\r\n",
        "      model.add(Dropout(0.5))\r\n",
        "      model.add(LSTM(units = 80, activation = 'tanh', return_sequences = True))\r\n",
        "      model.add(Dropout(0.5))\r\n",
        "      model.add(LSTM(units = 120, activation = 'tanh'))\r\n",
        "      model.add(Dropout(0.5))\r\n",
        "      model.add(Dense(units = 1))\r\n",
        "\r\n",
        "      model.compile(optimizer='sgd', loss = 'mean_squared_error')\r\n",
        "      model.fit(X_train, y_train, epochs=1, batch_size=64, verbose=0)\r\n",
        "\r\n",
        "      inputs = np.array(data_training_raw.tail(lookback))\r\n",
        "      inputs_reshaped = inputs.reshape(1, inputs.shape[0], inputs.shape[1])\r\n",
        "\r\n",
        "      y_pred = model.predict(inputs_reshaped)\r\n",
        "      \r\n",
        "      new_shit = np.append(y_train, y_pred)\r\n",
        "      new_shit_df = pd.DataFrame(data=new_shit)\r\n",
        "      historical_prices_plus_one[target_list[c]] = new_shit_df\r\n",
        "\r\n",
        "df_train_close = historical_prices_plus_one.set_index(\"timestamp\")\r\n",
        "df_train_close.index = pd.to_datetime(df_train_close.index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qivDgCIh9DyT"
      },
      "source": [
        "df_train_close_copy = df_train_close.copy()\r\n",
        "stocks = df_train_close.columns.tolist()\r\n",
        "\r\n",
        "df_train_list = [df_train_close]\r\n",
        "\r\n",
        "for df in df_train_list:\r\n",
        "    for s in stocks:\r\n",
        "        df[s] = df[s].diff()\r\n",
        "#redundant if you normalize from the get go @ LSTM input stage by taking pct change\r\n",
        "\r\n",
        "for df in df_train_list:\r\n",
        "    df.dropna(inplace=True)\r\n",
        "\r\n",
        "df_buy_in = df_train_close_copy.loc[today.strftime(\"%Y-%m-%d\")].sort_index().to_frame('Buy In')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMZKgywz-kYU"
      },
      "source": [
        "df_train_dcor_list = [df_distance_correlation(df) for df in df_train_list]\r\n",
        "H_close = build_corr_nx(df_train_dcor_list[0])\r\n",
        "H_master = H_close\r\n",
        "weights = nx.communicability_betweenness_centrality(H_master)\r\n",
        "centrality_to_portfolio_weights(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pI6oBN0-I_jh"
      },
      "source": [
        "capital = float(api.get_account().portfolio_value)\r\n",
        "\r\n",
        "alloc = discrete_allocation.DiscreteAllocation(\r\n",
        "    weights, \r\n",
        "    df_buy_in['Buy In'], \r\n",
        "    total_portfolio_value=capital\r\n",
        ")\r\n",
        "\r\n",
        "alloc = alloc.greedy_portfolio()[0]\r\n",
        "\r\n",
        "\r\n",
        "alloc_series = pd.Series(alloc, name='Desired Shares')\r\n",
        "alloc_series.index.name = 'Assets'\r\n",
        "alloc_series.reset_index\r\n",
        "df_alloc = alloc_series.sort_index().to_frame('Shares')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdlrOE7_e7xV"
      },
      "source": [
        "test = pd.DataFrame(df_alloc.values*df_buy_in.values,columns=[\"Total Price\"], index=df_alloc.index)\r\n",
        "\r\n",
        "allocation = pd.concat([df_alloc,df_buy_in,test],axis=1)\r\n",
        "print(allocation)\r\n",
        "\r\n",
        "print(\"\\n\")\r\n",
        "\r\n",
        "counter = 0\r\n",
        "for i in range(0, len(test[0:])):\r\n",
        "  counter += test.iloc[i,0]\r\n",
        "  print(counter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqG0NvIsqsY4"
      },
      "source": [
        "portfolio = api.list_positions()\r\n",
        "\r\n",
        "df_current = pd.DataFrame(columns = ['Assets', 'Current Shares']) \r\n",
        "\r\n",
        "for i in range(len(portfolio)):\r\n",
        "  #portfolio[i].side\r\n",
        "  print(portfolio[i].symbol, portfolio[i].qty)\r\n",
        "  df_current = df_current.append({'Assets':portfolio[i].symbol,'Current Shares':float(portfolio[i].qty)}, ignore_index=True)\r\n",
        "df_current = df_current.set_index(\"Assets\")\r\n",
        "df_current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL15SkTlsLrE"
      },
      "source": [
        "reconcil_df = pd.concat([df_alloc, df_current], axis=1).fillna(0)\r\n",
        "reconcil_df['Qty Diff'] = reconcil_df['Shares'] - reconcil_df['Current Shares']\r\n",
        "reconcil_df = reconcil_df.sort_values(by=\"Qty Diff\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpPOt26C1icd"
      },
      "source": [
        "for i in range(0, len(reconcil_df)):\r\n",
        "  symbol = reconcil_df['Qty Diff'].index[i]\r\n",
        "  qty = abs(reconcil_df['Qty Diff'][i])\r\n",
        "  if reconcil_df['Qty Diff'][i]>0:\r\n",
        "    side = 'buy'\r\n",
        "  else:\r\n",
        "    side = 'sell'\r\n",
        "  type = 'market'\r\n",
        "  time_in_force = 'gtc'\r\n",
        "  create_order(symbol, qty, side, type, time_in_force)\r\n",
        "  print(symbol, qty, side, type, time_in_force)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}